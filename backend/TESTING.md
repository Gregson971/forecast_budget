# Guide des Tests Backend

Ce document explique comment exÃ©cuter les tests pour le backend de Forecast Budget.

## ğŸ“‹ Table des matiÃ¨res

- [PrÃ©requis](#prÃ©requis)
- [Configuration](#configuration)
- [ExÃ©cution des tests](#exÃ©cution-des-tests)
- [Couverture de code](#couverture-de-code)
- [CI/CD](#cicd)
- [Bonnes pratiques](#bonnes-pratiques)

## ğŸ”§ PrÃ©requis

### Pour les tests locaux
- Python 3.11+
- PostgreSQL (ou Docker)
- Environnement virtuel Python activÃ©

### Pour les tests Docker
- Docker
- Docker Compose

## âš™ï¸ Configuration

### Variables d'environnement pour les tests

Les tests utilisent une base de donnÃ©es PostgreSQL sÃ©parÃ©e. CrÃ©ez un fichier `.env.test` (optionnel):

```bash
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/forecast_budget_test
SECRET_KEY=test_secret_key
ENVIRONMENT=development
```

## ğŸš€ ExÃ©cution des tests

### MÃ©thode 1: Avec Docker (RecommandÃ©)

La mÃ©thode la plus simple et isolÃ©e:

```bash
# ExÃ©cuter tous les tests
./run-tests.sh --docker

# Avec rapport de couverture
docker compose -f docker-compose.test.yml up --build --abort-on-container-exit
```

Avantages:
- Environnement complÃ¨tement isolÃ©
- Pas besoin d'installer PostgreSQL localement
- Configuration automatique de la base de donnÃ©es
- Nettoyage automatique aprÃ¨s les tests

### MÃ©thode 2: Localement avec le script

Utilisez le script `run-tests.sh` pour plus de flexibilitÃ©:

```bash
# ExÃ©cuter tous les tests
./run-tests.sh

# Avec rapport de couverture
./run-tests.sh --coverage

# ExÃ©cuter des tests spÃ©cifiques
./run-tests.sh --specific tests/use_cases/auth/

# Mode watch (nÃ©cessite pytest-watch)
./run-tests.sh --watch
```

### MÃ©thode 3: Directement avec pytest

Pour un contrÃ´le total:

```bash
# Activer l'environnement virtuel
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# ExÃ©cuter tous les tests
pytest tests/ -v

# Tests avec couverture
pytest tests/ --cov=app --cov-report=term-missing --cov-report=html

# Tests spÃ©cifiques
pytest tests/use_cases/auth/test_login_user.py -v

# Tests avec markers
pytest -m "not slow" -v

# Mode verbose avec dÃ©tails
pytest tests/ -vv --tb=short
```

## ğŸ“Š Couverture de code

### GÃ©nÃ©rer un rapport de couverture

```bash
# Rapport en terminal
pytest tests/ --cov=app --cov-report=term-missing

# Rapport HTML (plus dÃ©taillÃ©)
pytest tests/ --cov=app --cov-report=html
```

Le rapport HTML sera gÃ©nÃ©rÃ© dans `htmlcov/index.html`. Ouvrez-le dans un navigateur:

```bash
open htmlcov/index.html  # macOS
xdg-open htmlcov/index.html  # Linux
start htmlcov/index.html  # Windows
```

### InterprÃ©ter les rÃ©sultats

- **Vert**: Code testÃ©
- **Rouge**: Code non testÃ©
- **Jaune**: Code partiellement testÃ© (branches conditionnelles)

Objectif: **> 80% de couverture** pour le code mÃ©tier (use cases, domain).

## ğŸ”„ CI/CD

### GitHub Actions

Les tests s'exÃ©cutent automatiquement via GitHub Actions lors:
- Des push sur `main` et `develop`
- Des pull requests vers `main` et `develop`
- De modifications dans le dossier `backend/`

Voir le fichier `.github/workflows/backend-tests.yml` pour la configuration.

### Badges de statut

Ajoutez ces badges Ã  votre README principal:

```markdown
![Tests](https://github.com/votre-org/forecast_budget/workflows/Backend%20Tests/badge.svg)
[![codecov](https://codecov.io/gh/votre-org/forecast_budget/branch/main/graph/badge.svg)](https://codecov.io/gh/votre-org/forecast_budget)
```

## âœ… Bonnes pratiques

### Structure des tests

```
tests/
â”œâ”€â”€ domain/              # Tests des services de domaine
â”œâ”€â”€ infrastructure/      # Tests des implÃ©mentations (repos, SMS, etc.)
â”œâ”€â”€ use_cases/          # Tests des cas d'utilisation
â”‚   â”œâ”€â”€ auth/
â”‚   â”œâ”€â”€ expenses/
â”‚   â”œâ”€â”€ income/
â”‚   â””â”€â”€ user/
â””â”€â”€ conftest.py         # Fixtures partagÃ©es (si nÃ©cessaire)
```

### Conventions de nommage

- **Fichiers**: `test_<module>.py`
- **Classes**: `Test<ClassName>`
- **Fonctions**: `test_<action>_<expected_result>`

Exemple:
```python
def test_login_user_with_valid_credentials():
    """Test pour le cas d'utilisation de login avec identifiants valides."""
    # Arrange
    # Act
    # Assert
```

### Pattern AAA (Arrange-Act-Assert)

```python
def test_create_expense_success():
    # Arrange - PrÃ©parer les donnÃ©es et mocks
    user_id = "test-user-id"
    expense_data = {"amount": 50.0, "description": "Test"}

    # Act - ExÃ©cuter l'action
    result = create_expense_use_case.execute(user_id, expense_data)

    # Assert - VÃ©rifier le rÃ©sultat
    assert result.amount == 50.0
```

### Tests asynchrones

Pour les use cases asynchrones:

```python
import pytest

@pytest.mark.asyncio
async def test_async_function():
    result = await async_use_case.execute()
    assert result is not None
```

### Mocking

Utilisez `unittest.mock` pour les dÃ©pendances:

```python
from unittest.mock import Mock, AsyncMock

def test_with_mock():
    # Mock synchrone
    repo = Mock()
    repo.get_by_id.return_value = User(...)

    # Mock asynchrone
    sms_service = Mock()
    sms_service.send_sms = AsyncMock(return_value=True)
```

## ğŸ› Debugging

### ExÃ©cuter un test spÃ©cifique en mode debug

```bash
# Avec pytest
pytest tests/use_cases/auth/test_login_user.py::test_login_user_with_valid_credentials -vv -s

# Avec pdb (Python debugger)
pytest tests/use_cases/auth/test_login_user.py --pdb
```

### Voir les logs pendant les tests

```bash
# Afficher les print statements
pytest tests/ -s

# Avec niveau de log spÃ©cifique
pytest tests/ --log-cli-level=DEBUG
```

## ğŸ“ Commandes utiles

```bash
# Lister tous les tests sans les exÃ©cuter
pytest --collect-only

# ExÃ©cuter les tests qui ont Ã©chouÃ© lors de la derniÃ¨re exÃ©cution
pytest --lf

# ExÃ©cuter les tests jusqu'Ã  la premiÃ¨re erreur
pytest -x

# ExÃ©cuter en parallÃ¨le (nÃ©cessite pytest-xdist)
pytest -n auto

# GÃ©nÃ©rer un rapport JUnit XML (pour CI)
pytest --junitxml=test-results.xml
```

## ğŸ” RÃ©solution de problÃ¨mes

### "ModuleNotFoundError"

```bash
# VÃ©rifier que vous Ãªtes dans le bon rÃ©pertoire
pwd  # Doit Ãªtre dans /backend

# RÃ©installer les dÃ©pendances
pip install -r requirements.txt
```

### "Database connection error"

```bash
# VÃ©rifier que PostgreSQL est dÃ©marrÃ©
docker compose ps

# RedÃ©marrer PostgreSQL
docker compose restart postgres-test
```

### "Permission denied: ./run-tests.sh"

```bash
chmod +x run-tests.sh
```

## ğŸ“š Ressources

- [Pytest Documentation](https://docs.pytest.org/)
- [Pytest-cov Documentation](https://pytest-cov.readthedocs.io/)
- [Python unittest.mock](https://docs.python.org/3/library/unittest.mock.html)
- [Testing Best Practices](https://docs.python-guide.org/writing/tests/)

## ğŸ¯ Objectifs de couverture

| Module | Objectif | Actuel |
|--------|----------|--------|
| Use Cases | 95%+ | 85%+ |
| Domain Services | 90%+ | 85%+ |
| Repositories | 80%+ | 70%+ |
| API Routes | 70%+ | 0% (TODO) |
| **Total** | **80%+** | **49%** |

---

Pour toute question ou problÃ¨me, consultez la documentation ou ouvrez une issue.
